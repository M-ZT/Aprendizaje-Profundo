{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"#113D68\" size=6>Deep Learning con Python y Keras</font></h1>\n",
    "\n",
    "<h1><font color=\"#113D68\" size=5>Parte 3. Multilayer Perceptron</font></h1>\n",
    "\n",
    "<h1><font color=\"#113D68\" size=4>4. Usar modelos Keras con Scikit-learn</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#113D68\" size=3>Manuel Castillo Cara</font><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "More information about [Manuel Castillo-Cara](https://www.manuelcastillo.eu/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Puedes ver más cursos de Inteligencia Artificial, Machine Learning y Deep Learning en mi [página web](https://www.manuelcastillo.eu/udemy/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "\n",
    "* [0. Contexto](#section0)\n",
    "* [1. Introducción](#section1)\n",
    "* [2. Evaluar modelos con validación cruzada](#section2)\n",
    "* [3. Optimización de hiperparámetros](#section3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section0\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 0. Contexto</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta lección, aprenderemos cómo usar modelos de Deep Learning de Keras con Scikit-learn en Python. Después de completar esta lección, sabrá:\n",
    "* Cómo ajustar un modelo de Keras para usarlo con Scikit-learn.\n",
    "* Cómo evaluar fácilmente los modelos de Keras mediante la validación cruzada en scikit-learn.\n",
    "* Cómo ajustar los hiperparámetros del modelo de Keras mediante la búsqueda GridSearchCV en scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Eliminar warning\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\" size=6>1. Introducción</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn es una librería con todas las funciones de uso general y proporciona muchas utilidades que son útiles en el desarrollo de modelos de Deep Learning. No menos importante:\n",
    "* Evaluación de modelos utilizando métodos de remuestreo como la validación cruzada de k-fold.\n",
    "* Búsqueda y evaluación eficiente de hiperparámetros del modelo.\n",
    "\n",
    "La biblioteca de Keras proporciona un contenedor _(wrapper)_ conveniente para que los modelos de Deep Learning se utilicen como estimadores de clasificación o regresión en scikit-learn. En las siguientes secciones, trabajaremos a través de ejemplos del uso del contenedor `KerasClassifier`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalamos la librería scikeras primero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\" size=6>2. Evaluar modelos con validación cruzada </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las clases `KerasClassifier` y `KerasRegressor` en Keras toman un argumento `build_fn` que es el nombre de la función a llamar para crear su modelo. Debes definir una función llamada lo que quieras que defina tu modelo, lo compile y lo devuelva. En el siguiente ejemplo, \n",
    "\n",
    "1. Definimos una función `create_model()` que crea una red neuronal MLP.\n",
    "2. Pasamos este nombre de función a la clase `KerasClassifier` mediante el argumento `build_fn`.\n",
    "3. También pasamos argumentos adicionales de `epochs = 150` y `batch_size = 10`. Estos se agrupan automáticamente y se pasan a la función `fit()` que es llamada internamente por la clase `KerasClassifier`. \n",
    "4. Utilizamos la clase `StratifiedKFold` de Scikit-Learn con 10-fold. \n",
    "5. Usamos la función scikit-learn `cross_val_score()` para evaluar nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7161141514778138\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "???\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede ver que cuando se ajusta el modelo de Keras, la estimación de la precisión del modelo puede simplificarse en gran medida, en comparación con la enumeración manual de validación cruzada realizada en la lección anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\" size=6>3. Optimización de hiperparámetros</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, usamos `GridSearchCV` para evaluar diferentes configuraciones para nuestro modelo de red neuronal e informar sobre la combinación que proporciona el mejor rendimiento estimado. \n",
    "\n",
    "La función `create_model()` está definida para tomar dos argumentos `optimizer` e `init`, los cuales deben tener valores predeterminados. Específicamente, los hiperparámetros a establecer serán:\n",
    "* Optimizadores para establecer los pesos.\n",
    "* Inicializadores para los pesos.\n",
    "* Número de épocas para entrenar el modelo.\n",
    "* Batchs para variar el número de muestras antes de las actualizaciones de peso.\n",
    "\n",
    "Las opciones se especifican en un diccionario y se pasan a la configuración de la clase `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor: 0.730469 usando {'batch_size': 5, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.587240 (0.066317) con: {'batch_size': 5, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.649740 (0.004872) con: {'batch_size': 5, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.635417 (0.072333) con: {'batch_size': 5, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.716146 (0.030978) con: {'batch_size': 5, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.710938 (0.005524) con: {'batch_size': 5, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.704427 (0.023939) con: {'batch_size': 5, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.688802 (0.014731) con: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.697917 (0.008027) con: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.695312 (0.033299) con: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.727865 (0.018688) con: {'batch_size': 5, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.726562 (0.016573) con: {'batch_size': 5, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.730469 (0.013902) con: {'batch_size': 5, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.678385 (0.014382) con: {'batch_size': 5, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.700521 (0.034987) con: {'batch_size': 5, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.723958 (0.034104) con: {'batch_size': 5, 'epochs': 150, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.703125 (0.012758) con: {'batch_size': 5, 'epochs': 150, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.729167 (0.046256) con: {'batch_size': 5, 'epochs': 150, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.709635 (0.017566) con: {'batch_size': 5, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.626302 (0.004872) con: {'batch_size': 10, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.661458 (0.035132) con: {'batch_size': 10, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.709635 (0.034104) con: {'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.690104 (0.018136) con: {'batch_size': 10, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.694010 (0.024360) con: {'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.699219 (0.027805) con: {'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.634115 (0.006639) con: {'batch_size': 10, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.645833 (0.043537) con: {'batch_size': 10, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.717448 (0.051855) con: {'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.691406 (0.052698) con: {'batch_size': 10, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.716146 (0.003683) con: {'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.703125 (0.020915) con: {'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.610677 (0.070264) con: {'batch_size': 10, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.696615 (0.009744) con: {'batch_size': 10, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.703125 (0.022326) con: {'batch_size': 10, 'epochs': 150, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.716146 (0.019488) con: {'batch_size': 10, 'epochs': 150, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.718750 (0.022999) con: {'batch_size': 10, 'epochs': 150, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.716146 (0.029635) con: {'batch_size': 10, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.671875 (0.017758) con: {'batch_size': 20, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.598958 (0.065390) con: {'batch_size': 20, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.673177 (0.021710) con: {'batch_size': 20, 'epochs': 50, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.691406 (0.011500) con: {'batch_size': 20, 'epochs': 50, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.700521 (0.017566) con: {'batch_size': 20, 'epochs': 50, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.695312 (0.022999) con: {'batch_size': 20, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.636719 (0.032369) con: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.656250 (0.022326) con: {'batch_size': 20, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.712240 (0.027126) con: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.695312 (0.020915) con: {'batch_size': 20, 'epochs': 100, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.703125 (0.025315) con: {'batch_size': 20, 'epochs': 100, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.712240 (0.010253) con: {'batch_size': 20, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
      "0.669271 (0.043420) con: {'batch_size': 20, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n",
      "0.697917 (0.015733) con: {'batch_size': 20, 'epochs': 150, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
      "0.709635 (0.036966) con: {'batch_size': 20, 'epochs': 150, 'init': 'normal', 'optimizer': 'rmsprop'}\n",
      "0.710938 (0.014616) con: {'batch_size': 20, 'epochs': 150, 'init': 'normal', 'optimizer': 'adam'}\n",
      "0.720052 (0.032264) con: {'batch_size': 20, 'epochs': 150, 'init': 'uniform', 'optimizer': 'rmsprop'}\n",
      "0.710938 (0.024080) con: {'batch_size': 20, 'epochs': 150, 'init': 'uniform', 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# MLP for Pima Indians Dataset with 10-fold cross validation via sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "???\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = np.loadtxt(\"Datasets/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:, 8]\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(model= create_model, init='glorot_uniform', verbose=0)\n",
    "\n",
    "# grid search epochs, batch size and optimizer (2x3x3x2)\n",
    "???\n",
    "\n",
    "# summarize results\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
